<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project page for 'Resolution-Independent Neural Operators for Multi-Rate Sparse-View CT', introducing CTO, a resolution- and sampling-agnostic neural operator framework for sparse-view CT reconstruction.">
  <meta property="og:title" content="Resolution-Independent Neural Operators for Multi-Rate Sparse-View CT"/>
  <meta property="og:description" content="CTO is a unified CT reconstruction framework that generalizes across sampling rates and resolutions via rotation-equivariant discrete–continuous convolutions in sinogram and image domains."/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Resolution-Independent Neural Operators for Multi-Rate Sparse-View CT">
  <meta name="twitter:description" content="CTO: a resolution- and sampling-agnostic neural operator for multi-rate sparse-view CT, enabling fast and accurate reconstructions across acquisition setups.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="sparse-view CT, computed tomography, neural operators, resolution-independent, discrete-continuous convolutions, sinogram domain, rotation-equivariant convolutions">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Resolution-Independent Neural Operators for Multi-Rate Sparse-View CT</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Resolution-Independent Neural Operators for Multi-Rate Sparse-View CT</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://in.linkedin.com/in/aujasvit" target="_blank">Aujasvit Datta</a><sup>1,2,*</sup>,</span>
              <span class="author-block">
                <a href="https://pwang.pw/" target="_blank">Jiayun Wang</a><sup>1,*</sup>,</span>
              <span class="author-block">
                <a href="https://asadaali.com/" target="_blank">Asad Aali</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://armeet.ca/" target="_blank">Armeet Singh Jatyani</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://tensorlab.cms.caltech.edu/users/anima/" target="_blank">Anima Anandkumar</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup> Caltech &nbsp;&nbsp;
                <sup>2</sup> IIT Kanpur &nbsp;&nbsp;
                <sup>3</sup> Stanford University
                <br>In submission
              </span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates equal contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Paper PDF link -->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1K2upW71x1OKCnx8BNnC8UKSrCye_Vh6O/view?usp=sharing" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary / Slides link (optional / placeholder) -->
                <span class="link-block">
                  <a href="#" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-powerpoint"></i>
                    </span>
                    <span>Slides (coming soon)</span>
                  </a>
                </span>

                <!-- Code link -->
                <span class="link-block">
                  <a href="https://anonymous.4open.science/r/cto-8F3B/" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Sparse-view computed tomography (CT) reconstructs images from a limited number of X-ray projections to
            reduce radiation and scanning time, which makes reconstruction an ill-posed inverse problem. Deep learning
            methods achieve high-fidelity reconstructions but often overfit to a fixed acquisition setup, failing to
            generalize across sampling rates and image resolutions. For example, convolutional neural networks (CNNs)
            use the same learned kernels across resolutions, leading to artifacts when data resolution changes.
          </p>
          <p>
            We propose Computed Tomography neural Operator (CTO), a unified CT reconstruction framework that extends
            to continuous function space, enabling generalization (without retraining) across sampling rates and image
            resolutions. CTO operates jointly in the sinogram and image domains through rotation-equivariant
            discrete–continuous convolutions parametrized in the function space, making it inherently resolution- and
            sampling-agnostic.
          </p>
          <p>
            Empirically, CTO enables consistent multi-sampling-rate and cross-resolution performance, with on average
            &gt; 4 dB PSNR gain over CNNs. Compared to state-of-the-art diffusion methods, CTO is 500× faster in inference
            time with on average 3 dB gain. Empirical results also validate our design choices behind CTO’s
            sinogram-space operator learning and rotation-equivariant convolution. Overall, CTO outperforms
            state-of-the-art baselines across sampling rates and resolutions, offering a scalable and generalizable
            solution that makes automated CT reconstruction more practical for deployment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@misc{datta_resolution_independent_cto,
  title        = {Resolution-Independent Neural Operators for Multi-Rate Sparse-View CT},
  author       = {Aujasvit Datta and Jiayun Wang and Asad Aali and Armeet Singh Jatyani and Anima Anandkumar},
  note         = {In submission},
}
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Acknowledgment: This work is supported in part by ONR (MURI grant N000142312654 and N000142012786).
            A.D. is supported in part by the Undergraduate Research Fellowships (SURF) at Caltech. J.W. is supported
            in part by the Pritzker AI+Science initiative and Schmidt Sciences. A.A. is supported in part by the Bren
            endowed chair and the AI2050 senior fellow program at Schmidt Sciences.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
