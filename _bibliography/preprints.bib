
@article{wang2024lung,
  author    = {Jiayun Wang and Oleksii Ostras and Masashi Sode and Bahareh Tolooshams and Zongyi Li and Kamyar Azizzadenesheli and Giammarco Pinton and Anima Anandkumar},
  title     = {Ultrasound Lung Aeration Map via Physics-Aware Neural Operators},
  journal   = {In preparation for submission to Nature},
  year      = {2025},
  abbr={arXiv},
       preview={lusno.png},
         website      = {https://pwang.pw/lungNO/},
  pdf          = {https://arxiv.org/pdf/2501.01157},
    html={https://arxiv.org/abs/2501.01157},
  selected     = {true},
    abstract     = {Lung ultrasound is a growing modality in clinics for diagnosing and monitoring acute and chronic lung diseases due to its low cost and accessibility. Lung ultrasound works by emitting diagnostic pulses, receiving pressure waves and converting them into radio frequency (RF) data, which are then processed into B-mode images with beamformers for radiologists to interpret. However, unlike conventional ultrasound for soft tissue anatomical imaging, lung ultrasound interpretation is complicated by complex reverberations from the pleural interface caused by the inability of ultrasound to penetrate air. The indirect B-mode images make interpretation highly dependent on reader expertise, requiring years of training, which limits its widespread use despite its potential for high accuracy in skilled hands.
To address these challenges and democratize ultrasound lung imaging as a reliable diagnostic tool, we propose LUNA, an AI model that directly reconstructs lung aeration maps from RF data, bypassing the need for traditional beamformers and indirect interpretation of B-mode images. },
}

@article{tolooshams2023neural,
  author = {Bahareh Tolooshams and Lydia Lin and Thierri Callier and Jiayun Wang and Sanvi Pal and Aditi Chandrashekar and Claire M. Rabut and Sumner Norman and Mikhail G. Shapiro and Charles Liu and Kamyar Azizzadenesheli and Richard A. Andersen and Anima Anandkumar},
  title = {Neural operators for accelerated functional ultrasound imaging},
    pdf          = {nofus.pdf},
           preview={fus.png},
  abbr={arXiv},
  journal = {In preparation for submission to Nature Methods},
  year = {2025}
}


article{wang2024fast,
  author    = {Jiayun Wang and Yousuf Aborahama and Julius Berner and Zongyi Li and Kamyar Azizzadenesheli and Lihong V. Wang and Anima Anandkumar},
  title     = {Fast and Resolution-Invariant 3D Photoacoustic Computed Tomography via Operator Learning},
  journal   = {Nature Communications (in submission)},
  year      = {2024},
  abbr={arXiv}
}

@inproceedings{wang2024beyond,
  title={Beyond Closure Models: Learning Chaotic-Systems via Physics-Informed Neural Operators},
  author={Wang, Chuwei and Berner, Julius and Li, Zongyi and Zhou, Di and Wang, Jiayun and Bae, Jane and Anandkumar, Anima},
  booktitle={submission to ICLR},
  year={2025},
  abbr={arXiv},
       preview={closure.png},
       pdf={https://arxiv.org/pdf/2408.05177},
  html={https://arxiv.org/abs/2408.05177},
  abstract={Accurately predicting the long-term behavior of chaotic systems is crucial for various applications such as climate modeling. However, achieving such predictions typically requires iterative computations over a dense spatiotemporal grid to account for the unstable nature of chaotic systems, which is expensive and impractical in many real-world situations. An alternative approach to such a full-resolved simulation is using a coarse grid and then correcting its errors through a \textit{closure model}, which approximates the overall information from fine scales not captured in the coarse-grid simulation. Recently, ML approaches have been used for closure modeling, but they typically require a large number of training samples from expensive fully-resolved simulations (FRS). In this work, we prove an even more fundamental limitation, i.e., the standard approach to learning closure models suffers from a large approximation error for generic problems, no matter how large the model is, and it stems from the non-uniqueness of the mapping. We propose an alternative end-to-end learning approach using a physics-informed neural operator (PINO) that overcomes this limitation by not using a closure model or a coarse-grid solver.},
}

@inproceedings{Yao2024open,
  author    = {Jin Yao and Hao Gu and Xuweiyi Chen and Jiayun Wang and Zezhou Cheng},
  title     = {Open Vocabulary Monocular 3D Object Detection},
  booktitle={submission},
  year      = {2025},
  abbr={arXiv},
       preview={3ddet.jpg},
  pdf          = {https://arxiv.org/pdf/2411.16833},
  html          = {https://arxiv.org/abs/2411.16833},
  website      = {https://uva-computer-vision-lab.github.io/ovmono3d/},
  code         = {https://github.com/UVA-Computer-Vision-Lab/ovmono3d},
  abstract     = {In this work, we pioneer the study of open-vocabulary monocular 3D object detection, a novel task that aims to detect and localize objects in 3D space from a single RGB image without limiting detection to a predefined set of categories. We formalize this problem, establish baseline methods, and introduce a class-agnostic approach that leverages open-vocabulary 2D detectors and lifts 2D bounding boxes into 3D space. Our approach decouples the recognition and localization of objects in 2D from the task of estimating 3D bounding boxes, enabling generalization across unseen categories. Additionally, we propose a target-aware evaluation protocol to address inconsistencies in existing datasets, improving the reliability of model performance assessment. Extensive experiments on the Omni3D dataset demonstrate the effectiveness of the proposed method in zero-shot 3D detection for novel object categories, validating its robust generalization capabilities. Our method and evaluation protocols contribute towards the development of open-vocabulary object detection models that can effectively operate in real-world, category-diverse environments.},
}




%not included
%SSL PDE
%fus